#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Firestore ë°ì´í„° ë°±ì—… ìŠ¤í¬ë¦½íŠ¸"""

import os
import sys
import json
import csv
import argparse
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any
from google.cloud import firestore
from google.oauth2 import service_account

# Windows í™˜ê²½ì—ì„œ UTF-8 ì¶œë ¥ ì„¤ì •
if sys.platform == "win32":
    import codecs
    sys.stdout = codecs.getwriter("utf-8")(sys.stdout.detach())
    sys.stderr = codecs.getwriter("utf-8")(sys.stderr.detach())

class FirestoreExporter:
    """Firestore ë°ì´í„° ë‚´ë³´ë‚´ê¸° ë„êµ¬"""
    
    def __init__(self, project_id: str, credentials_path: str = None):
        self.project_id = project_id
        
        if credentials_path:
            credentials = service_account.Credentials.from_service_account_file(credentials_path)
            self.db = firestore.Client(project=project_id, credentials=credentials)
        else:
            # í™˜ê²½ë³€ìˆ˜ë‚˜ ê¸°ë³¸ ì¸ì¦ ì‚¬ìš©
            self.db = firestore.Client(project=project_id)
    
    def list_collections(self) -> List[str]:
        """ëª¨ë“  ì»¬ë ‰ì…˜ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°"""
        collections = self.db.collections()
        return [col.id for col in collections]
    
    def export_collection_to_json(self, collection_name: str, output_dir: str = "backup") -> str:
        """ì»¬ë ‰ì…˜ì„ JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        docs = self.db.collection(collection_name).stream()
        data = []
        
        for doc in docs:
            doc_data = doc.to_dict()
            doc_data['_id'] = doc.id
            doc_data['_collection'] = collection_name
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì²˜ë¦¬
            for key, value in doc_data.items():
                if hasattr(value, 'timestamp'):  # Firestore timestamp
                    doc_data[key] = value.isoformat()
            
            data.append(doc_data)
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        Path(output_dir).mkdir(exist_ok=True)
        
        # íŒŒì¼ëª…ì— íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"{output_dir}/{collection_name}_{timestamp}.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"âœ… {collection_name}: {len(data)}ê°œ ë¬¸ì„œ â†’ {output_file}")
        return output_file
    
    def export_collection_to_csv(self, collection_name: str, output_dir: str = "backup") -> str:
        """ì»¬ë ‰ì…˜ì„ CSV íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        docs = self.db.collection(collection_name).stream()
        data = []
        
        for doc in docs:
            doc_data = doc.to_dict()
            doc_data['_id'] = doc.id
            doc_data['_collection'] = collection_name
            
            # ì¤‘ì²©ëœ ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            for key, value in doc_data.items():
                if isinstance(value, (dict, list)):
                    doc_data[key] = json.dumps(value, ensure_ascii=False, default=str)
                elif hasattr(value, 'timestamp'):
                    doc_data[key] = value.isoformat()
            
            data.append(doc_data)
        
        if not data:
            print(f"âš ï¸ {collection_name}: ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        Path(output_dir).mkdir(exist_ok=True)
        
        # CSV íŒŒì¼ ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"{output_dir}/{collection_name}_{timestamp}.csv"
        
        with open(output_file, 'w', newline='', encoding='utf-8') as f:
            if data:
                writer = csv.DictWriter(f, fieldnames=data[0].keys())
                writer.writeheader()
                writer.writerows(data)
        
        print(f"âœ… {collection_name}: {len(data)}ê°œ ë¬¸ì„œ â†’ {output_file}")
        return output_file
    
    def export_all_collections(self, format: str = "json", output_dir: str = "backup"):
        """ëª¨ë“  ì»¬ë ‰ì…˜ì„ ë‚´ë³´ë‚´ê¸°"""
        collections = self.list_collections()
        print(f"ğŸ“‹ ë°œê²¬ëœ ì»¬ë ‰ì…˜: {collections}")
        
        exported_files = []
        for collection_name in collections:
            try:
                if format.lower() == "json":
                    file_path = self.export_collection_to_json(collection_name, output_dir)
                elif format.lower() == "csv":
                    file_path = self.export_collection_to_csv(collection_name, output_dir)
                else:
                    print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹: {format}")
                    continue
                
                if file_path:
                    exported_files.append(file_path)
                    
            except Exception as e:
                print(f"âŒ {collection_name} ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
        
        print(f"\nğŸ‰ ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {len(exported_files)}ê°œ íŒŒì¼")
        return exported_files
    
    def query_and_export(self, collection_name: str, field: str, operator: str, value: Any, 
                        output_dir: str = "backup", format: str = "json") -> str:
        """ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ë§Œ ë‚´ë³´ë‚´ê¸°"""
        query = self.db.collection(collection_name).where(field, operator, value)
        docs = query.stream()
        
        data = []
        for doc in docs:
            doc_data = doc.to_dict()
            doc_data['_id'] = doc.id
            data.append(doc_data)
        
        if not data:
            print(f"âš ï¸ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {field} {operator} {value}")
            return None
        
        # íŒŒì¼ ì €ì¥
        Path(output_dir).mkdir(exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        if format.lower() == "json":
            output_file = f"{output_dir}/{collection_name}_filtered_{timestamp}.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2, default=str)
        else:
            output_file = f"{output_dir}/{collection_name}_filtered_{timestamp}.csv"
            with open(output_file, 'w', newline='', encoding='utf-8') as f:
                if data:
                    writer = csv.DictWriter(f, fieldnames=data[0].keys())
                    writer.writeheader()
                    writer.writerows(data)
        
        print(f"âœ… í•„í„°ë§ëœ ë°ì´í„°: {len(data)}ê°œ ë¬¸ì„œ â†’ {output_file}")
        return output_file

def main():
    parser = argparse.ArgumentParser(description='Firestore ë°ì´í„° ë‚´ë³´ë‚´ê¸° ë„êµ¬')
    parser.add_argument('--project-id', required=True, help='GCP í”„ë¡œì íŠ¸ ID')
    parser.add_argument('--credentials', help='ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--collection', help='íŠ¹ì • ì»¬ë ‰ì…˜ë§Œ ë‚´ë³´ë‚´ê¸°')
    parser.add_argument('--format', choices=['json', 'csv'], default='json', help='ì¶œë ¥ í˜•ì‹')
    parser.add_argument('--output-dir', default='backup', help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--all', action='store_true', help='ëª¨ë“  ì»¬ë ‰ì…˜ ë‚´ë³´ë‚´ê¸°')
    
    # í•„í„°ë§ ì˜µì…˜
    parser.add_argument('--filter-field', help='í•„í„°ë§í•  í•„ë“œëª…')
    parser.add_argument('--filter-operator', choices=['==', '!=', '<', '<=', '>', '>=', 'in', 'not-in'], 
                       help='í•„í„°ë§ ì—°ì‚°ì')
    parser.add_argument('--filter-value', help='í•„í„°ë§ ê°’')
    
    args = parser.parse_args()
    
    # Firestore ë‚´ë³´ë‚´ê¸° ë„êµ¬ ì´ˆê¸°í™”
    exporter = FirestoreExporter(args.project_id, args.credentials)
    
    try:
        if args.all:
            # ëª¨ë“  ì»¬ë ‰ì…˜ ë‚´ë³´ë‚´ê¸°
            exporter.export_all_collections(args.format, args.output_dir)
        elif args.collection:
            # íŠ¹ì • ì»¬ë ‰ì…˜ ë‚´ë³´ë‚´ê¸°
            if args.filter_field and args.filter_operator and args.filter_value:
                # í•„í„°ë§ ì ìš©
                exporter.query_and_export(
                    args.collection, 
                    args.filter_field, 
                    args.filter_operator, 
                    args.filter_value,
                    args.output_dir,
                    args.format
                )
            else:
                # ì „ì²´ ì»¬ë ‰ì…˜
                if args.format == 'json':
                    exporter.export_collection_to_json(args.collection, args.output_dir)
                else:
                    exporter.export_collection_to_csv(args.collection, args.output_dir)
        else:
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ë ‰ì…˜ ëª©ë¡ í‘œì‹œ
            collections = exporter.list_collections()
            print("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ë ‰ì…˜:")
            for col in collections:
                print(f"  â€¢ {col}")
            print("\nğŸ’¡ ì‚¬ìš©ë²•:")
            print(f"  python {__file__} --project-id {args.project_id} --collection COLLECTION_NAME")
            print(f"  python {__file__} --project-id {args.project_id} --all")
    
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())