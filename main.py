import os
import json
import base64
import logging
import re
import mimetypes
import asyncio
import time
from typing import Dict, Any, List, Tuple, Optional, Callable
from functools import wraps
from fastapi import FastAPI, File, UploadFile, HTTPException, Form
from fastapi.responses import JSONResponse, FileResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
import google.auth
import google.auth.transport.requests
from google.cloud import storage, spanner, secretmanager
import requests, markdown
from requests import exceptions as requests_exceptions
from dotenv import load_dotenv
from google.auth.exceptions import DefaultCredentialsError
from google.oauth2 import service_account
import aiohttp

app = FastAPI(static_files_directory="public", title="Gemini RAG Chatbot API", version="1.0.0")

@app.on_event("startup")
async def startup_event():
    """ì•± ì‹œì‘ ì‹œ ì—°ê²° ì´ˆê¸°í™”"""
    logger.info("ğŸš€ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ - í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì´ˆê¸°í™”")
    initialize_clients()

@app.on_event("shutdown") 
async def shutdown_event():
    """ì•± ì¢…ë£Œ ì‹œ ì—°ê²° ì •ë¦¬"""
    logger.info("ğŸ”„ ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ - ì—°ê²° ì •ë¦¬")
    global spanner_client
    if spanner_client:
        spanner_client.close()
load_dotenv()

class Config:
    @staticmethod
    def get_env(name: str) -> str:
        if name not in os.environ:
            raise EnvironmentError(f"âŒ í™˜ê²½ë³€ìˆ˜ '{name}'ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return os.environ[name]

    PROJECT_ID = get_env('PROJECT_ID')
    LOCATION_ID = get_env('LOCATION_ID')
    MODEL_ID = get_env('MODEL_ID')
    DATASTORE_ID = get_env('DATASTORE_ID')
    DATASTORE_LOCATION = get_env('DATASTORE_LOCATION')
    SYSTEM_PROMPT_PATH = get_env('SYSTEM_PROMPT_PATH')
    SPANNER_INSTANCE_ID = get_env('SPANNER_INSTANCE_ID')
    SPANNER_DATABASE_ID = get_env('SPANNER_DATABASE_ID')
    SPANNER_TABLE_NAME = get_env('SPANNER_TABLE_NAME')

    API_ENDPOINT = f"https://{LOCATION_ID}-aiplatform.googleapis.com"
    MODEL_ENDPOINT_URL = f"{API_ENDPOINT}/v1/projects/{PROJECT_ID}/locations/{LOCATION_ID}/publishers/google/models/{MODEL_ID}:generateContent"
    DATASTORE_PATH = f"projects/{PROJECT_ID}/locations/{DATASTORE_LOCATION}/collections/default_collection/dataStores/{DATASTORE_ID}"

    @staticmethod
    def get_system_instruction():
        try:
            with open(Config.SYSTEM_PROMPT_PATH, "r", encoding="utf-8") as f:
                return f.read()
        except FileNotFoundError:
            logger.warning(f"System prompt file not found: {Config.SYSTEM_PROMPT_PATH}")
            return "You are a helpful AI assistant."
        except Exception as e:
            logger.error(f"Error reading system prompt file: {e}")
            return "You are a helpful AI assistant."

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

SERVICE_ACCOUNT_PATH = "keys/cheom-kdb-test1-faf5cf87a1fd.json"

def get_service_account_credentials():
    """Secret Manager ë˜ëŠ” ë¡œì»¬ íŒŒì¼ì—ì„œ ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    use_secret_manager = os.environ.get("USE_SECRET_MANAGER", "false").lower() == "true"
    
    if use_secret_manager:
        try:
            # Secret Managerì—ì„œ ì„œë¹„ìŠ¤ ê³„ì • JSON ê°€ì ¸ì˜¤ê¸°
            service_account_json = os.environ.get("SERVICE_ACCOUNT_JSON")
            if service_account_json:
                # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì§ì ‘ JSON ë¬¸ìì—´ ì‚¬ìš© (Cloud Run secrets)
                credentials_info = json.loads(service_account_json)
                return service_account.Credentials.from_service_account_info(
                    credentials_info,
                    scopes=["https://www.googleapis.com/auth/cloud-platform"]
                )
            else:
                # Secret Manager APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
                project_id = os.environ.get("PROJECT_ID", "cheom-kdb-test1")
                secret_name = f"projects/{project_id}/secrets/service-account-key/versions/latest"
                
                # ê¸°ë³¸ ì¸ì¦ìœ¼ë¡œ Secret Manager í´ë¼ì´ì–¸íŠ¸ ìƒì„±
                client = secretmanager.SecretManagerServiceClient()
                response = client.access_secret_version(request={"name": secret_name})
                secret_value = response.payload.data.decode("UTF-8")
                
                credentials_info = json.loads(secret_value)
                return service_account.Credentials.from_service_account_info(
                    credentials_info,
                    scopes=["https://www.googleapis.com/auth/cloud-platform"]
                )
        except Exception as e:
            logger.warning(f"Secret Managerì—ì„œ ì¸ì¦ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}, ê¸°ë³¸ ì¸ì¦ ì‚¬ìš©")
            return None
    else:
        # ë¡œì»¬ íŒŒì¼ ì‚¬ìš©
        if os.path.exists(SERVICE_ACCOUNT_PATH):
            return service_account.Credentials.from_service_account_file(
                SERVICE_ACCOUNT_PATH,
                scopes=["https://www.googleapis.com/auth/cloud-platform"]
            )
    
    return None

# ì „ì—­ í´ë¼ì´ì–¸íŠ¸ ë° ë°ì´í„°ë² ì´ìŠ¤ ê°ì²´
credentials = None
storage_client = None
spanner_client = None
spanner_database = None

def initialize_clients():
    """í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ë° ì—°ê²° í’€ ì„¤ì •"""
    global credentials, storage_client, spanner_client, spanner_database
    
    try:
        # Secret Manager ë˜ëŠ” ë¡œì»¬ íŒŒì¼ì—ì„œ ì¸ì¦ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        credentials = get_service_account_credentials()
        
        if credentials:
            project_id = credentials.project_id
            logger.info(f"âœ… ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦ ì„±ê³µ - project_id: {project_id}")
        else:
            # ê¸°ë³¸ ì¸ì¦ ì‚¬ìš© (Cloud Run í™˜ê²½ì—ì„œ)
            credentials, project_id = google.auth.default(
                scopes=["https://www.googleapis.com/auth/cloud-platform"]
            )
            logger.info(f"âœ… ê¸°ë³¸ ì¸ì¦ ì‚¬ìš© - project_id: {project_id}")
        
        # Storage í´ë¼ì´ì–¸íŠ¸
        storage_client = storage.Client(credentials=credentials, project=project_id)
        
        # Spanner í´ë¼ì´ì–¸íŠ¸ (ì—°ê²° í’€ ì„¤ì •)
        spanner_client = spanner.Client(
            credentials=credentials, 
            project=project_id
        )
        
        # ë°ì´í„°ë² ì´ìŠ¤ ê°ì²´ ë¯¸ë¦¬ ìƒì„± (ì¬ì‚¬ìš©)
        instance = spanner_client.instance(Config.SPANNER_INSTANCE_ID)
        spanner_database = instance.database(Config.SPANNER_DATABASE_ID)
        
        logger.info(f"âœ… ì¸ì¦ ë° ì—°ê²° í’€ ì´ˆê¸°í™” ì™„ë£Œ - project_id: {project_id}")
        
    except Exception as e:
        logger.critical("âŒ ì¸ì¦ ë˜ëŠ” ì—°ê²° í’€ ì´ˆê¸°í™” ì˜¤ë¥˜", exc_info=True)
        credentials = None
        storage_client = None
        spanner_client = None
        spanner_database = None

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤í–‰
initialize_clients()

# === ì»¤ìŠ¤í…€ ì˜ˆì™¸ í´ë˜ìŠ¤ ===
class VertexAIAPIError(Exception):
    def __init__(self, message: str, status_code: int, error_body: str):
        super().__init__(message)
        self.status_code = status_code
        self.error_body = error_body

class SpannerConnectionError(Exception):
    """Spanner ì—°ê²° ê´€ë ¨ ì˜¤ë¥˜"""
    pass

class TripleExtractionError(Exception):
    """Triple ì¶”ì¶œ ê´€ë ¨ ì˜¤ë¥˜"""
    pass

class DocumentProcessingError(Exception):
    """ë¬¸ì„œ ì²˜ë¦¬ ê´€ë ¨ ì˜¤ë¥˜"""
    pass

# === ì¬ì‹œë„ ë°ì½”ë ˆì´í„° ===
def retry_async(max_attempts: int = 3, delay: float = 1.0, backoff: float = 2.0, 
               exceptions: tuple = (Exception,)):
    """ë¹„ë™ê¸° í•¨ìˆ˜ìš© ì¬ì‹œë„ ë°ì½”ë ˆì´í„°"""
    def decorator(func: Callable):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            last_exception = None
            
            for attempt in range(max_attempts):
                try:
                    return await func(*args, **kwargs)
                except exceptions as e:
                    last_exception = e
                    if attempt == max_attempts - 1:
                        break
                    
                    wait_time = delay * (backoff ** attempt)
                    logger.warning(f"í•¨ìˆ˜ {func.__name__} ì¬ì‹œë„ {attempt + 1}/{max_attempts} "
                                 f"(ë‹¤ìŒ ì‹œë„ê¹Œì§€ {wait_time:.1f}ì´ˆ ëŒ€ê¸°): {str(e)}")
                    await asyncio.sleep(wait_time)
            
            # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
            logger.error(f"í•¨ìˆ˜ {func.__name__} {max_attempts}íšŒ ì¬ì‹œë„ ëª¨ë‘ ì‹¤íŒ¨")
            raise last_exception
            
        return wrapper
    return decorator

# === Circuit Breaker íŒ¨í„´ ===
class CircuitBreaker:
    """Circuit Breaker íŒ¨í„´ êµ¬í˜„"""
    def __init__(self, failure_threshold: int = 5, timeout: float = 60.0):
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.failure_count = 0
        self.last_failure_time = None
        self.state = "CLOSED"  # CLOSED, OPEN, HALF_OPEN
    
    def __call__(self, func: Callable):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            if self.state == "OPEN":
                if time.time() - self.last_failure_time < self.timeout:
                    raise HTTPException(
                        status_code=503, 
                        detail="ì„œë¹„ìŠ¤ ì¼ì‹œì  ì´ìš© ë¶ˆê°€ (Circuit Breaker OPEN)"
                    )
                else:
                    self.state = "HALF_OPEN"
            
            try:
                result = await func(*args, **kwargs)
                self._on_success()
                return result
            except Exception as e:
                self._on_failure()
                raise e
        
        return wrapper
    
    def _on_success(self):
        self.failure_count = 0
        self.state = "CLOSED"
    
    def _on_failure(self):
        self.failure_count += 1
        self.last_failure_time = time.time()
        if self.failure_count >= self.failure_threshold:
            self.state = "OPEN"
            logger.error(f"Circuit Breaker OPEN - {self.failure_count}íšŒ ì—°ì† ì‹¤íŒ¨")

# Circuit Breaker ì¸ìŠ¤í„´ìŠ¤
vertex_circuit_breaker = CircuitBreaker(failure_threshold=3, timeout=30.0)
spanner_circuit_breaker = CircuitBreaker(failure_threshold=5, timeout=60.0)

def extract_document_links(vertex_result: Dict[str, Any]) -> List[Dict[str, str]]:
    """Vertex AI Search ê²°ê³¼ì—ì„œ ë¬¸ì„œ ë§í¬ ì •ë³´ë¥¼ ì¶”ì¶œ"""
    links = []
    try:
        # groundingMetadataì—ì„œ ë¬¸ì„œ ì •ë³´ ì¶”ì¶œ
        if 'candidates' in vertex_result:
            candidate = vertex_result['candidates'][0]
            if 'groundingMetadata' in candidate:
                grounding_supports = candidate['groundingMetadata'].get('groundingSupports', [])
                
                for support in grounding_supports:
                    if 'segment' in support:
                        segment = support['segment']
                        if 'text' in segment and 'retrievalMetadata' in segment:
                            metadata = segment['retrievalMetadata']
                            if 'source' in metadata:
                                source = metadata['source']
                                # GCS ë§í¬ë§Œ í•„í„°ë§
                                if source.startswith('gs://') or 'storage.googleapis.com' in source:
                                    # íŒŒì¼ëª…ì„ ì œëª©ìœ¼ë¡œ ì¶”ì¶œ
                                    title = source.split('/')[-1] if '/' in source else source
                                    title = title.replace('.pdf', '').replace('.txt', '').replace('.docx', '')
                                    
                                    links.append({
                                        'title': title,
                                        'url': source
                                    })
        
        # ì¤‘ë³µ ì œê±°
        seen = set()
        unique_links = []
        for link in links:
            if link['url'] not in seen:
                seen.add(link['url'])
                unique_links.append(link)
                
        return unique_links[:5]  # ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ ë°˜í™˜
        
    except Exception as e:
        logger.warning(f"ë¬¸ì„œ ë§í¬ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return []

def extract_keywords_from_prompt(user_prompt: str) -> List[str]:
    """ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œ"""
    # ê¸°ë³¸ì ì¸ ë¶ˆìš©ì–´ ì œê±° ë° í‚¤ì›Œë“œ ì¶”ì¶œ
    stop_words = {'ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì˜', 'ì—', 'ì—ì„œ', 'ë¡œ', 'ìœ¼ë¡œ', 'ì™€', 'ê³¼', 'í•˜ë‹¤', 'ë˜ë‹¤', 'ìˆë‹¤', 'ì—†ë‹¤', 'ì´ë‹¤', 'ì•„ë‹ˆë‹¤', 
                  'ë¬´ì—‡', 'ì–´ë–¤', 'ì–´ë””', 'ì–¸ì œ', 'ì™œ', 'ì–´ë–»ê²Œ', 'ëˆ„êµ¬', 'ëª‡', 'ì–¼ë§ˆ', 'ì¸ê°€ìš”', 'ì…ë‹ˆê¹Œ', 'ìŠµë‹ˆê¹Œ', 'ë‚˜ìš”', 'ê¹Œìš”', 'ëŠ”ì§€', 'ì¸ì§€'}
    
    # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ë‹¨ì–´ ë¶„ë¦¬
    words = re.sub(r'[^\w\s]', ' ', user_prompt).split()
    
    # ë¶ˆìš©ì–´ ì œê±° ë° 2ê¸€ì ì´ìƒ ë‹¨ì–´ë§Œ ì¶”ì¶œ
    keywords = [word for word in words if len(word) >= 2 and word not in stop_words]
    
    return keywords[:5]  # ìµœëŒ€ 5ê°œ í‚¤ì›Œë“œë§Œ ì‚¬ìš©

@spanner_circuit_breaker
@retry_async(max_attempts=3, delay=1.0, exceptions=(SpannerConnectionError, Exception))
async def query_spanner_triples(user_prompt: str) -> List[str]:
    """ìµœì í™”ëœ Spanner íŠ¸ë¦¬í”Œ ì¿¼ë¦¬ (ì—°ê²° í’€ ì‚¬ìš©)"""
    if not spanner_database:
        logger.error("Spanner ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        raise SpannerConnectionError("Spanner ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
    try:
        logger.info(json.dumps({
            "stage": "spanner_query_start",
            "input": user_prompt
        }))

        # í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = extract_keywords_from_prompt(user_prompt)
        
        logger.info(json.dumps({
            "stage": "keywords_extracted",
            "input": user_prompt,
            "keywords": keywords
        }))

        # ì „ì—­ ë°ì´í„°ë² ì´ìŠ¤ ê°ì²´ ì¬ì‚¬ìš© (ì—°ê²° í’€ í™œìš©)
        
        all_triples = []
        
        # 1. ì›ë³¸ í”„ë¡¬í”„íŠ¸ë¡œ ê²€ìƒ‰
        query = f"""
        SELECT subject, predicate, object FROM `{Config.SPANNER_TABLE_NAME}`
        WHERE subject LIKE @term OR predicate LIKE @term OR object LIKE @term
        LIMIT 10
        """
        params = {"term": f"%{user_prompt}%"}
        param_types = {"term": spanner.param_types.STRING}

        with spanner_database.snapshot() as snapshot:
            results = snapshot.execute_sql(query, params=params, param_types=param_types)
            original_triples = [f"{row[0]} {row[1]} {row[2]}" for row in results]
            all_triples.extend(original_triples)

        # 2. í‚¤ì›Œë“œë³„ë¡œ ê²€ìƒ‰ (ì¤‘ë³µ ì œê±°)
        for keyword in keywords:
            params = {"term": f"%{keyword}%"}
            with spanner_database.snapshot() as snapshot:
                results = snapshot.execute_sql(query, params=params, param_types=param_types)
                keyword_triples = [f"{row[0]} {row[1]} {row[2]}" for row in results]
                for triple in keyword_triples:
                    if triple not in all_triples:
                        all_triples.append(triple)
        
        # ìµœëŒ€ 15ê°œê¹Œì§€ë§Œ ë°˜í™˜
        triples = all_triples[:15]

        logger.info(json.dumps({
            "stage": "spanner_query_success",
            "input": user_prompt,
            "keywords": keywords,
            "original_results": len(original_triples),
            "total_result_count": len(triples),
            "results": triples
        }))

        return triples

    except Exception as e:
        logger.error(json.dumps({
            "stage": "spanner_query_error",
            "input": user_prompt,
            "error": str(e),
            "error_type": type(e).__name__
        }), exc_info=True)
        
        # êµ¬ì²´ì ì¸ ì˜ˆì™¸ ìœ í˜•ì— ë”°ë¼ ì²˜ë¦¬
        if "Connection" in str(e) or "timeout" in str(e).lower():
            raise SpannerConnectionError(f"Spanner ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        else:
            raise TripleExtractionError(f"Triple ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")

async def extract_triple_from_prompt(user_prompt: str) -> Tuple[str, str, str]:
    prompt = f"""
ë‹¤ìŒ ë¬¸ì¥ì„ (	
subject,predicate,object) tripleë¡œ ë¶„í•´í•´ì¤˜.
í˜•ì‹: subject=..., predicate=..., object=...

ë¬¸ì¥: "{user_prompt}"
"""
    payload = {
        "contents": [{"role": "user", "parts": [{"text": prompt}]}],
        "generationConfig": {"temperature": 0.0}
    }

    response = await _call_vertex_api(payload)
    text = response["candidates"][0]["content"]["parts"][0]["text"]

    # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì¶”ì¶œ
    match = re.search(r"subject\s*=\s*(.+?),\s*predicate\s*=\s*(.+?),\s*object\s*=\s*(.*)", text)
    if match:
        return match.group(1).strip(), match.group(2).strip(), match.group(3).strip()
    else:
        raise ValueError("Triple ì¶”ì¶œ ì‹¤íŒ¨: " + text)


async def _build_vertex_payload(
    user_prompt: str,
    conversation_history: List[Dict[str, Any]],
    image_file: Optional[UploadFile],
    preloaded_triples: Optional[List[str]] = None
) -> Tuple[Dict[str, Any], List[Dict[str, Any]]]:
    user_content_parts = []
    if image_file:
        image_base64 = base64.b64encode(await image_file.read()).decode('utf-8')
        user_content_parts.append({"inlineData": {"mimeType": image_file.content_type, "data": image_base64}})

    if user_prompt:
        user_content_parts.append({"text": user_prompt})

    current_contents = conversation_history + [{"role": "user", "parts": user_content_parts}]

    # ğŸ§  Triple grounding: ë¯¸ë¦¬ ë°›ì•„ì˜¨ ê²Œ ìˆìœ¼ë©´ ì“°ê³ , ì—†ìœ¼ë©´ ì¶”ì¶œ
    if preloaded_triples is not None:
        triples = preloaded_triples
    else:
        try:
            triples = await query_spanner_triples(user_prompt)
        except Exception as e:
            logger.warning(f"Triple ì¶”ì¶œ ë˜ëŠ” ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            triples = []

    # ğŸ“ grounding ë‚´ìš© system prompt ì•ì— ì‚½ì…
    if triples:
        triple_text = "\n".join(triples)
        current_contents.insert(0, {
            "role": "user",
            "parts": [{"text": f"[Spanner Triple Grounding]\n{triple_text}"}]
        })

    payload = {
        "systemInstruction": {"parts": [{"text": Config.get_system_instruction()}]},
        "contents": current_contents,
        "tools": [{"retrieval": {"vertexAiSearch": {"datastore": Config.DATASTORE_PATH}}}],
        "generationConfig": {
            "temperature": 0,
            "maxOutputTokens": 8192,
            "topP": 0.3
        }
    }

    return payload, current_contents


@vertex_circuit_breaker
@retry_async(max_attempts=3, delay=2.0, exceptions=(VertexAIAPIError, aiohttp.ClientError))
async def _call_vertex_api(payload: Dict[str, Any]) -> Dict[str, Any]:
    if not credentials:
        raise VertexAIAPIError("ì¸ì¦ ì •ë³´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤", 500, "No credentials")

    try:
        auth_req = google.auth.transport.requests.Request()
        credentials.refresh(auth_req)

        headers = {
            'Authorization': f'Bearer {credentials.token}',
            'Content-Type': 'application/json; charset=utf-8'
        }

        timeout = aiohttp.ClientTimeout(total=300)
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.post(Config.MODEL_ENDPOINT_URL, headers=headers, json=payload) as response:
                if not response.ok:
                    error_body = await response.text()
                    error_msg = f"Vertex AI API í˜¸ì¶œ ì‹¤íŒ¨ (HTTP {response.status})"
                    
                    # ìƒíƒœ ì½”ë“œë³„ ìƒì„¸ ë©”ì‹œì§€
                    if response.status == 400:
                        error_msg += " - ì˜ëª»ëœ ìš”ì²­ í˜•ì‹"
                    elif response.status == 401:
                        error_msg += " - ì¸ì¦ ì‹¤íŒ¨"
                    elif response.status == 403:
                        error_msg += " - ì ‘ê·¼ ê¶Œí•œ ì—†ìŒ"
                    elif response.status == 429:
                        error_msg += " - ìš”ì²­ í•œë„ ì´ˆê³¼"
                    elif response.status >= 500:
                        error_msg += " - ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜"
                    
                    raise VertexAIAPIError(error_msg, response.status, error_body)
                
                try:
                    return await response.json()
                except aiohttp.ContentTypeError as e:
                    response_text = await response.text()
                    logger.error(f"Vertex AI API returned non-JSON response: {response_text[:500]}")
                    raise VertexAIAPIError(f"ì„œë²„ê°€ ë¹„ì •ìƒì ì¸ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤", response.status, response_text)
                except Exception as e:
                    response_text = await response.text()
                    logger.error(f"JSON parsing failed: {str(e)}, Response: {response_text[:500]}")
                    raise VertexAIAPIError(f"ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {str(e)}", response.status, response_text)
                
    except aiohttp.ClientError as e:
        logger.error(f"Vertex AI API ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {str(e)}")
        raise VertexAIAPIError(f"ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì˜¤ë¥˜: {str(e)}", 503, str(e))
    except Exception as e:
        logger.error(f"Vertex AI API ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
        raise VertexAIAPIError(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}", 500, str(e))



@app.post('/api/generate')
async def generate_content(userPrompt: str = Form(""), conversationHistory: str = Form("[]"), imageFile: Optional[UploadFile] = File(None)):
    if not credentials:
        raise HTTPException(status_code=503, detail="ì„œë²„ ì¸ì¦ ì‹¤íŒ¨")

    try:
        conversation_history = json.loads(conversationHistory)

        # Triple ì •ë³´ ì¡°íšŒ
        triples = await query_spanner_triples(userPrompt)

        # ğŸš€ ë‹¨ì¼ API í˜¸ì¶œë¡œ Triple + Vertex AI Search í†µí•© ì²˜ë¦¬
        payload, full_history = await _build_vertex_payload(userPrompt, conversation_history, imageFile, triples)
        result = await _call_vertex_api(payload)
        
        # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        response_text = result['candidates'][0]['content']['parts'][0]['text']
        
        # RAG ë¬¸ì„œ ë§í¬ ì¶”ì¶œ
        document_links = extract_document_links(result)
        
        # ë¬¸ì„œ ë§í¬ë¥¼ ì‘ë‹µì— ì¶”ê°€
        if document_links:
            link_text = "\n\nğŸ‘‰ ê´€ë ¨ ë¬¸ì„œ ë³´ê¸°:\n"
            for link in document_links:
                link_text += f"- {link['title']}\n"
            response_text += link_text

        logger.info(json.dumps({
            "stage": "unified_answer_generated",
            "user_prompt": userPrompt,
            "triples_used": triples,
            "response": response_text,
            "document_links_count": len(document_links)
        }, ensure_ascii=False))

        return JSONResponse({
            "summary_answer": response_text,
            "document_links": document_links,
            "updatedHistory": full_history
        })

    except SpannerConnectionError as e:
        logger.error(f"Spanner ì—°ê²° ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(
            status_code=503, 
            detail="ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        )
    except TripleExtractionError as e:
        logger.warning(f"Triple ì¶”ì¶œ ì˜¤ë¥˜ (ì„œë¹„ìŠ¤ ê³„ì†): {str(e)}")
        # Triple ê²€ìƒ‰ ì‹¤íŒ¨í•´ë„ Vertex AI Searchë§Œìœ¼ë¡œ ë‹µë³€ ì‹œë„
        try:
            payload, full_history = await _build_vertex_payload(userPrompt, conversation_history, imageFile, [])
            result = await _call_vertex_api(payload)
            response_text = result['candidates'][0]['content']['parts'][0]['text']
            
            return JSONResponse({
                "summary_answer": f"âš ï¸ ì¼ë¶€ ì •ë³´ ê²€ìƒ‰ì— ë¬¸ì œê°€ ìˆì—ˆì§€ë§Œ, ê°€ëŠ¥í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.\n\n{response_text}",
                "document_links": extract_document_links(result),
                "updatedHistory": full_history
            })
        except Exception:
            raise HTTPException(
                status_code=503,
                detail="ì§€ì‹ë² ì´ìŠ¤ ê²€ìƒ‰ì— ë¬¸ì œê°€ ìˆì–´ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
    except VertexAIAPIError as e:
        logger.error(f"Vertex AI API ì˜¤ë¥˜: {str(e)}")
        if e.status_code == 429:
            raise HTTPException(
                status_code=429,
                detail="ìš”ì²­ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
        elif e.status_code >= 500:
            raise HTTPException(
                status_code=503,
                detail="AI ì„œë¹„ìŠ¤ì— ì¼ì‹œì  ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
        else:
            raise HTTPException(
                status_code=400,
                detail="ìš”ì²­ ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì…ë ¥ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
            )
    except HTTPException:
        # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì „ë‹¬
        raise
    except Exception as e:
        logger.exception("ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ")
        raise HTTPException(
            status_code=500,
            detail="ì„œë¹„ìŠ¤ì— ì¼ì‹œì  ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        )


@app.get("/gcs/{bucket_name}/{file_path:path}")
async def proxy_gcs_file(bucket_name: str, file_path: str):
    if not storage_client:
        raise HTTPException(status_code=503, detail="ìŠ¤í† ë¦¬ì§€ ì¸ì¦ ì‹¤íŒ¨")

    try:
        bucket = storage_client.bucket(bucket_name)
        blob = bucket.blob(file_path)
        if not blob.exists():
            raise HTTPException(status_code=404, detail="íŒŒì¼ ì—†ìŒ")

        def iterfile():
            with blob.open("rb") as f:
                yield from f

        content_type, _ = mimetypes.guess_type(file_path)
        content_type = content_type or "application/octet-stream"
        headers = {'Content-Disposition': f'inline; filename="{os.path.basename(file_path)}"'}
        return StreamingResponse(iterfile(), media_type=content_type, headers=headers)
    except Exception as e:
        logger.error("GCS í”„ë¡ì‹œ ì˜¤ë¥˜", exc_info=True)
        raise HTTPException(status_code=500, detail="íŒŒì¼ ì½ê¸° ì‹¤íŒ¨")

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ - ì—°ê²° ìƒíƒœ ë° Circuit Breaker ìƒíƒœ í™•ì¸"""
    status = {
        "status": "healthy",
        "connections": {
            "spanner": spanner_database is not None,
            "storage": storage_client is not None,
            "credentials": credentials is not None
        },
        "circuit_breakers": {
            "vertex_ai": {
                "state": vertex_circuit_breaker.state,
                "failure_count": vertex_circuit_breaker.failure_count
            },
            "spanner": {
                "state": spanner_circuit_breaker.state,
                "failure_count": spanner_circuit_breaker.failure_count
            }
        }
    }
    
    # ì—°ê²° ìƒíƒœë‚˜ Circuit Breaker ìƒíƒœ í™•ì¸
    connections_healthy = all(status["connections"].values())
    circuit_breakers_healthy = all(
        cb["state"] == "CLOSED" for cb in status["circuit_breakers"].values()
    )
    
    if not connections_healthy or not circuit_breakers_healthy:
        status["status"] = "unhealthy"
        return JSONResponse(status_code=503, content=status)
    
    return JSONResponse(content=status)

@app.get("/")
async def serve_root():
    return FileResponse("public/index.html")

app.mount("/", StaticFiles(directory="public"), name="static")

@app.get("/{full_path:path}")
async def serve_spa(full_path: str):
    if full_path.startswith("api") or os.path.exists(os.path.join("public", full_path)):
        raise HTTPException(status_code=404, detail="Not Found")
    return FileResponse("public/index.html")