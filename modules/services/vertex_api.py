"""Discovery Engine API í˜¸ì¶œ ì„œë¹„ìŠ¤"""
import logging
import hashlib
from typing import Dict, Any, Optional
from functools import lru_cache
from google.cloud import discoveryengine_v1 as discoveryengine

from ..config import Config
from ..auth import get_discovery_client

logger = logging.getLogger(__name__)

# Discovery Engine ì„¤ì •
PROJECT_ID = "cheom-kdb-test1"
LOCATION = "global"
ENGINE_ID = "test_1753406039510"

# ì‘ë‹µ ìºì‹œ (ë©”ëª¨ë¦¬ ê¸°ë°˜)
_response_cache = {}

def _get_cache_key(query: str) -> str:
    """ì¿¼ë¦¬ì—ì„œ ìºì‹œ í‚¤ ìƒì„±"""
    return hashlib.md5(query.encode('utf-8')).hexdigest()

def _get_cached_response(query: str) -> Optional[Dict[str, Any]]:
    """ìºì‹œëœ ì‘ë‹µ ë°˜í™˜"""
    cache_key = _get_cache_key(query)
    return _response_cache.get(cache_key)

def _cache_response(query: str, response: Dict[str, Any]) -> None:
    """ì‘ë‹µì„ ìºì‹œì— ì €ì¥ (ìµœëŒ€ 100ê°œ, LRU)"""
    cache_key = _get_cache_key(query)
    
    # ìºì‹œ í¬ê¸° ì œí•œ
    if len(_response_cache) >= 100:
        # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±° (ê°„ë‹¨í•œ FIFO)
        oldest_key = next(iter(_response_cache))
        del _response_cache[oldest_key]
    
    _response_cache[cache_key] = response

class DiscoveryEngineAPIError(Exception):
    """Discovery Engine API í˜¸ì¶œ ì˜¤ë¥˜"""
    def __init__(self, message: str, details: str = ""):
        super().__init__(message)
        self.details = details

def _truncate_query(query: str, max_length: int = 2000) -> str:
    """ì¿¼ë¦¬ë¥¼ ìµœëŒ€ ê¸¸ì´ë¡œ ìë¥´ê¸°"""
    if len(query) <= max_length:
        return query
    
    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸° ì‹œë„
    sentences = query.split('.')
    truncated = ""
    
    for sentence in sentences:
        if len(truncated + sentence + ".") <= max_length - 50:  # ì—¬ìœ ë¶„ 50ì
            truncated += sentence + "."
        else:
            break
    
    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸°ê°€ ì•ˆë˜ë©´ ë‹¨ìˆœ ìë¥´ê¸°
    if not truncated or len(truncated) < 100:
        truncated = query[:max_length-50] + "..."
    
    logger.warning(f"ì¿¼ë¦¬ê°€ {len(query)}ìì—ì„œ {len(truncated)}ìë¡œ ì¶•ì†Œë¨")
    return truncated

def _format_references(references: list) -> str:
    """ì°¸ì¡° ë¬¸ì„œë¥¼ ë§í¬ë¡œ í¬ë§·íŒ…"""
    if not references:
        return ""
    
    formatted_refs = []
    for i, ref in enumerate(references[:5], 1):  # ìµœëŒ€ 5ê°œë§Œ
        title = ref.get('title', f'ì°¸ê³ ë¬¸ì„œ{i}')
        uri = ref.get('uri', '')
        relevance = ref.get('relevance_score', 0)
        
        # íŒŒì¼ëª…ì„ ë” ì½ê¸° ì‰½ê²Œ ë³€í™˜
        display_name = title.replace('naver_blog_', '').replace('_', ' ').title()
        if not display_name or display_name == title:
            display_name = f"ì°¸ê³ ë¬¸ì„œ {i}"
        
        # GCS URIë¥¼ API í”„ë¡ì‹œ ë§í¬ë¡œ ë³€í™˜
        if uri.startswith('gs://'):
            # gs://bucket/path -> /gcs/bucket/path
            bucket_and_path = uri[5:]  # 'gs://' ì œê±°
            proxy_link = f"/gcs/{bucket_and_path}"
            formatted_refs.append(f"ğŸ“„ [{display_name}]({proxy_link}) *(ê´€ë ¨ë„: {relevance:.1f})*")
        else:
            formatted_refs.append(f"ğŸ“„ {display_name}")
    
    return "\n\n---\n**ğŸ“š ì°¸ê³  ë¬¸ì„œ:**\n" + "\n".join(formatted_refs)

def search_discovery_engine(query: str, max_results: int = 20) -> Dict[str, Any]:
    """Discovery Engine ê²€ìƒ‰ API í˜¸ì¶œ - ë¬¸ì„œ ë°œê²¬ìš© (ìƒ˜í”Œ ì½”ë“œ ê¸°ë°˜ ê°œì„ )"""
    try:
        # ClientOptionsìœ¼ë¡œ ìµœì í™”ëœ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        from google.api_core.client_options import ClientOptions
        from google.cloud.discoveryengine_v1 import SearchServiceClient
        
        client_options = (
            ClientOptions(api_endpoint=f"{LOCATION}-discoveryengine.googleapis.com")
            if LOCATION != "global"
            else None
        )
        search_client = SearchServiceClient(client_options=client_options)
        
        # ì¿¼ë¦¬ ê¸¸ì´ ì œí•œ ì ìš©
        truncated_query = _truncate_query(query)
        
        # Search Serving Config ê²½ë¡œ (ìƒ˜í”Œ ì½”ë“œì™€ ì¼ì¹˜)
        serving_config = f"projects/{PROJECT_ID}/locations/{LOCATION}/collections/default_collection/engines/{ENGINE_ID}/servingConfigs/default_config"
        
        # ê°œì„ ëœ ê²€ìƒ‰ ìš”ì²­ ê°ì²´ ìƒì„± (summary_spec ì¶”ê°€)
        request = discoveryengine.SearchRequest(
            serving_config=serving_config,
            query=truncated_query,
            page_size=max_results,
            content_search_spec=discoveryengine.SearchRequest.ContentSearchSpec(
                snippet_spec=discoveryengine.SearchRequest.ContentSearchSpec.SnippetSpec(
                    return_snippet=True,
                    max_snippet_count=3
                ),
                # ê²€ìƒ‰ ìš”ì•½ ê¸°ëŠ¥ ì¶”ê°€
                summary_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec(
                    summary_result_count=5,
                    include_citations=True,
                    ignore_adversarial_query=True,
                    ignore_non_summary_seeking_query=False,
                    model_prompt_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec.ModelPromptSpec(
                        preamble="í•œêµ­ì–´ë¡œ ìƒì„¸í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."
                    ),
                    model_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec.ModelSpec(
                        version="stable"
                    )
                )
            ),
            # ë§ì¶¤ë²• êµì •ë§Œ ì‚¬ìš© (query_expansion_specëŠ” multi-datastoreì—ì„œ ì§€ì› ì•ˆë¨)
            spell_correction_spec=discoveryengine.SearchRequest.SpellCorrectionSpec(
                mode=discoveryengine.SearchRequest.SpellCorrectionSpec.Mode.AUTO
            )
        )
        
        # ê²€ìƒ‰ API í˜¸ì¶œ
        response = search_client.search(request)
        
        # ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
        search_results = []
        for result in response.results:
            doc = result.document
            doc_data = {
                "id": doc.id,
                "title": doc.derived_struct_data.get("title", "ì œëª©ì—†ìŒ"),
                "link": doc.derived_struct_data.get("link", ""),
                "snippets": []
            }
            
            # ìŠ¤ë‹ˆí« ì¶”ì¶œ
            if "snippets" in doc.derived_struct_data:
                for snippet_info in doc.derived_struct_data["snippets"]:
                    if snippet_info.get("snippet_status") == "SUCCESS":
                        # HTML íƒœê·¸ ì œê±°
                        snippet_text = snippet_info.get("snippet", "").replace("<b>", "").replace("</b>", "")
                        doc_data["snippets"].append(snippet_text)
            
            search_results.append(doc_data)
        
        # ê²€ìƒ‰ ìš”ì•½ ì •ë³´ ì¶”ì¶œ
        search_summary = None
        if hasattr(response, 'summary') and response.summary:
            search_summary = {
                "summary_text": response.summary.summary_text if hasattr(response.summary, 'summary_text') else "",
                "safety_attributes": response.summary.safety_attributes if hasattr(response.summary, 'safety_attributes') else None,
                "summary_skipped_reasons": response.summary.summary_skipped_reasons if hasattr(response.summary, 'summary_skipped_reasons') else []
            }
        
        logger.info(f"ê²€ìƒ‰ API ê²°ê³¼: {len(search_results)}ê°œ ë¬¸ì„œ ë°œê²¬, ìš”ì•½: {'ìˆìŒ' if search_summary else 'ì—†ìŒ'}")
        
        return {
            "results": search_results,
            "total_size": response.total_size if hasattr(response, 'total_size') else len(search_results),
            "query": truncated_query,
            "summary": search_summary
        }
        
    except Exception as e:
        logger.error(f"Discovery Engine ê²€ìƒ‰ API í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}")
        return {
            "results": [],
            "total_size": 0,
            "query": query,
            "error": str(e)
        }

def _build_context_from_search_results(search_results: list, search_summary: dict = None, max_context_length: int = 1500) -> str:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ Answer API ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ìš”ì•½ í¬í•¨)"""
    if not search_results and not search_summary:
        return ""
    
    context_parts = []
    current_length = 0
    
    # ê²€ìƒ‰ ìš”ì•½ì´ ìˆìœ¼ë©´ ìš°ì„  í¬í•¨
    if search_summary and search_summary.get("summary_text"):
        summary_context = f"[ê²€ìƒ‰ ìš”ì•½]\n{search_summary['summary_text']}\n\n"
        if len(summary_context) <= max_context_length // 3:  # ì»¨í…ìŠ¤íŠ¸ì˜ 1/3ê¹Œì§€ë§Œ ìš”ì•½ì— í• ë‹¹
            context_parts.append(summary_context)
            current_length += len(summary_context)
    
    # ê²€ìƒ‰ ê²°ê³¼ ë¬¸ì„œë“¤ ì¶”ê°€
    for i, result in enumerate(search_results[:8], 1):  # ìš”ì•½ì´ ìˆìœ¼ë©´ ë¬¸ì„œ ìˆ˜ ì¡°ê¸ˆ ì¤„ì„
        title = result.get("title", f"ë¬¸ì„œ{i}")
        snippets = result.get("snippets", [])
        
        if not snippets:
            continue
            
        # ë¬¸ì„œë³„ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        doc_context = f"[ë¬¸ì„œ{i}: {title}]\n"
        
        for snippet in snippets[:2]:  # ë¬¸ì„œë‹¹ ìµœëŒ€ 2ê°œ ìŠ¤ë‹ˆí«
            if current_length + len(doc_context) + len(snippet) > max_context_length:
                break
                
            doc_context += f"- {snippet.strip()}\n"
        
        if current_length + len(doc_context) <= max_context_length:
            context_parts.append(doc_context)
            current_length += len(doc_context)
        else:
            break
    
    context = "\n".join(context_parts)
    logger.info(f"ê²€ìƒ‰ ê²°ê³¼ ì»¨í…ìŠ¤íŠ¸ ìƒì„±: {len(context)}ì, {len(context_parts)}ê°œ ì„¹ì…˜ (ìš”ì•½ í¬í•¨: {'ì˜ˆ' if search_summary else 'ì•„ë‹ˆì˜¤'})")
    
    return context

def call_discovery_engine_with_search_context(query: str) -> Dict[str, Any]:
    """í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼: ê²€ìƒ‰ API + Answer API"""
    try:
        # 1ë‹¨ê³„: ê²€ìƒ‰ APIë¡œ ê´€ë ¨ ë¬¸ì„œ ë°œê²¬
        search_results = search_discovery_engine(query, max_results=15)
        
        if not search_results.get("results"):
            logger.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ ê¸°ì¡´ Answer API ì‚¬ìš©")
            return call_discovery_engine(query)
        
        # 2ë‹¨ê³„: ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ìš”ì•½ í¬í•¨)
        search_context = _build_context_from_search_results(
            search_results["results"], 
            search_results.get("summary")
        )
        
        if not search_context:
            logger.warning("ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨, ê¸°ì¡´ Answer API ì‚¬ìš©")
            return call_discovery_engine(query)
        
        # 3ë‹¨ê³„: ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ê°•í™”ëœ ì¿¼ë¦¬ ìƒì„±
        enhanced_query = f"""ì§ˆë¬¸: {query}

ê´€ë ¨ ì°¸ê³  ì •ë³´:
{search_context}

ìœ„ ì°¸ê³  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ìƒì„¸í•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”."""
        
        # 4ë‹¨ê³„: Answer API í˜¸ì¶œ
        logger.info(f"í•˜ì´ë¸Œë¦¬ë“œ ì¿¼ë¦¬ ê¸¸ì´: {len(enhanced_query)}ì")
        result = call_discovery_engine(enhanced_query)
        
        # ê²€ìƒ‰ ê²°ê³¼ ë©”íƒ€ë°ì´í„° ì¶”ê°€
        result["search_metadata"] = {
            "search_docs_found": len(search_results["results"]),
            "context_used": len(search_context),
            "hybrid_approach": True
        }
        
        return result
        
    except Exception as e:
        logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ ì˜¤ë¥˜: {str(e)}, ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´")
        return call_discovery_engine(query)

async def call_discovery_engine_with_search_context_async(query: str) -> Dict[str, Any]:
    """í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ ë¹„ë™ê¸° ë²„ì „"""
    # ìºì‹œ ë¨¼ì € í™•ì¸
    cached_response = _get_cached_response(query)
    if cached_response:
        logger.info(f"ìºì‹œëœ ì‘ë‹µ ì‚¬ìš© (í•˜ì´ë¸Œë¦¬ë“œ ë¹„ë™ê¸°): {query[:50]}...")
        return cached_response
    
    # í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ ì‚¬ìš©
    return call_discovery_engine_with_search_context(query)

async def call_discovery_engine_async(query: str) -> Dict[str, Any]:
    """Discovery Engine API ë¹„ë™ê¸° í˜¸ì¶œ"""
    # ìºì‹œ ë¨¼ì € í™•ì¸
    cached_response = _get_cached_response(query)
    if cached_response:
        logger.info(f"ìºì‹œëœ ì‘ë‹µ ì‚¬ìš© (ë¹„ë™ê¸°): {query[:50]}...")
        return cached_response
    
    # ìºì‹œê°€ ì—†ìœ¼ë©´ ë™ê¸° í•¨ìˆ˜ í˜¸ì¶œ
    return call_discovery_engine(query)

def call_discovery_engine(query: str) -> Dict[str, Any]:
    """Discovery Engine API í˜¸ì¶œ (ìƒ˜í”Œ ì½”ë“œ ê¸°ë°˜ ê°œì„ )"""
    try:
        # ìºì‹œ í™•ì¸
        cached_response = _get_cached_response(query)
        if cached_response:
            logger.info(f"ìºì‹œëœ ì‘ë‹µ ì‚¬ìš©: {query[:50]}...")
            return cached_response
        
        # ClientOptionsìœ¼ë¡œ ìµœì í™”ëœ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        from google.api_core.client_options import ClientOptions
        
        client_options = (
            ClientOptions(api_endpoint=f"{LOCATION}-discoveryengine.googleapis.com")
            if LOCATION != "global"
            else None
        )
        client = discoveryengine.ConversationalSearchServiceClient(client_options=client_options)
        
        # ì¿¼ë¦¬ ê¸¸ì´ ì œí•œ ì ìš©
        truncated_query = _truncate_query(query)
        
        # Search Serving Config ë¦¬ì†ŒìŠ¤ ê²½ë¡œ êµ¬ì„±
        serving_config = f"projects/{PROJECT_ID}/locations/{LOCATION}/collections/default_collection/engines/{ENGINE_ID}/servingConfigs/default_serving_config"
        
        # Query Understanding ì„¤ì • (ìƒ˜í”Œ ì½”ë“œ ê¸°ë°˜ ê°œì„ )
        query_understanding_spec = discoveryengine.AnswerQueryRequest.QueryUnderstandingSpec(
            query_rephraser_spec=discoveryengine.AnswerQueryRequest.QueryUnderstandingSpec.QueryRephraserSpec(
                disable=False,
                max_rephrase_steps=1,
            ),
            query_classification_spec=discoveryengine.AnswerQueryRequest.QueryUnderstandingSpec.QueryClassificationSpec(
                types=[
                    discoveryengine.AnswerQueryRequest.QueryUnderstandingSpec.QueryClassificationSpec.Type.ADVERSARIAL_QUERY,
                    discoveryengine.AnswerQueryRequest.QueryUnderstandingSpec.QueryClassificationSpec.Type.NON_ANSWER_SEEKING_QUERY,
                ]
            ),
        )
        
        # Answer Generation ì„¤ì • (ìƒ˜í”Œ ì½”ë“œ ê¸°ë°˜ ê°œì„ )
        answer_generation_spec = discoveryengine.AnswerQueryRequest.AnswerGenerationSpec(
            ignore_adversarial_query=False,
            ignore_non_answer_seeking_query=False,
            ignore_low_relevant_content=False,
            # ìµœì‹  ëª¨ë¸ ì‚¬ìš©
            model_spec=discoveryengine.AnswerQueryRequest.AnswerGenerationSpec.ModelSpec(
                model_version="gemini-2.0-flash-001/answer_gen/v1"
            ),
            prompt_spec=discoveryengine.AnswerQueryRequest.AnswerGenerationSpec.PromptSpec(
                preamble="í•œêµ­ì–´ë¡œ ì •í™•í•˜ê³  ìƒì„¸í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”. ê°€ê²©ì´ë‚˜ ë¹„ìš© ì •ë³´ê°€ ìˆë‹¤ë©´ êµ¬ì²´ì ìœ¼ë¡œ í¬í•¨í•´ì£¼ì„¸ìš”.",
            ),
            include_citations=True,
            answer_language_code="ko",
        )
        
        # ìš”ì²­ ê°ì²´ ìƒì„±
        request = discoveryengine.AnswerQueryRequest(
            serving_config=serving_config,
            query=discoveryengine.Query(text=truncated_query),
            session=None,
            query_understanding_spec=query_understanding_spec,
            answer_generation_spec=answer_generation_spec,
        )
        
        # API í˜¸ì¶œ
        response = client.answer_query(request)
        
        # ì°¸ì¡° ì •ë³´ ì¶”ì¶œ
        references = []
        if response.answer and hasattr(response.answer, 'references') and response.answer.references:
            references = [
                {
                    "content": ref.chunk_info.content if ref.chunk_info else "",
                    "relevance_score": ref.chunk_info.relevance_score if ref.chunk_info else 0.0,
                    "title": ref.chunk_info.document_metadata.title if ref.chunk_info and ref.chunk_info.document_metadata else "",
                    "uri": ref.chunk_info.document_metadata.uri if ref.chunk_info and ref.chunk_info.document_metadata else ""
                }
                for ref in response.answer.references
            ]
        
        # ë‹µë³€ í…ìŠ¤íŠ¸ì— ì°¸ì¡° ë§í¬ ì¶”ê°€
        answer_text = response.answer.answer_text if response.answer else ""
        reference_links = _format_references(references)
        enhanced_answer = answer_text + reference_links
        
        # ì‘ë‹µ ë³€í™˜
        result = {
            "answer_text": enhanced_answer,
            "citations": [
                {
                    "start_index": c.start_index,
                    "end_index": c.end_index,
                    "reference_ids": [s.reference_id for s in c.sources] if c.sources else []
                }
                for c in response.answer.citations
            ] if response.answer and response.answer.citations else [],
            "references": references
        }
        
        # ìºì‹œì— ì €ì¥
        _cache_response(query, result)
        
        return result
        
    except Exception as e:
        logger.error(f"Discovery Engine API í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}")
        raise DiscoveryEngineAPIError(f"Discovery Engine API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}", str(e))

async def generate_triple_based_answer_async(user_prompt: str, triples: list) -> Dict[str, Any]:
    """Triple ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Discovery Engineì„ í†µí•´ ë‹µë³€ ìƒì„± (ë¹„ë™ê¸°) - í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼"""
    if not triples:
        return await call_discovery_engine_with_search_context_async(user_prompt)
    
    # Triple ì •ë³´ë¥¼ ì ì ˆíˆ ì œí•œí•´ì„œ í¬í•¨
    max_triple_length = 800  # Triple ì •ë³´ ìµœëŒ€ ê¸¸ì´ (ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ ê³µê°„ í™•ë³´)
    triple_text = "\n".join(triples)
    
    if len(triple_text) > max_triple_length:
        triple_text = triple_text[:max_triple_length] + "..."
        logger.warning(f"Triple í…ìŠ¤íŠ¸ê°€ {len(triple_text)}ìë¡œ ì¶•ì†Œë¨")
    
    # í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼: ê²€ìƒ‰ìœ¼ë¡œ ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
    search_results = search_discovery_engine(user_prompt, max_results=10)
    search_context = _build_context_from_search_results(
        search_results.get("results", []), 
        search_results.get("summary"),
        max_context_length=700  # Tripleê³¼ ê· í˜• ë§ì¶¤
    )
    
    # ê°•í™”ëœ ì¿¼ë¦¬ ìƒì„±
    enhanced_query = f"""ì§ˆë¬¸: {user_prompt}

ë°ì´í„°ë² ì´ìŠ¤ Triple ì •ë³´:
{triple_text}

ê²€ìƒ‰ëœ ì¶”ê°€ ì°¸ê³  ì •ë³´:
{search_context}

ìœ„ ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì •í™•í•˜ê³  ìƒì„¸í•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”."""
    
    result = await call_discovery_engine_async(enhanced_query)
    
    # ë©”íƒ€ë°ì´í„° ì¶”ê°€
    result["hybrid_metadata"] = {
        "triple_count": len(triples),
        "search_docs_found": len(search_results.get("results", [])),
        "combined_approach": True
    }
    
    return result

def generate_triple_based_answer(user_prompt: str, triples: list) -> Dict[str, Any]:
    """Triple ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Discovery Engineì„ í†µí•´ ë‹µë³€ ìƒì„± - í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼"""
    if not triples:
        return call_discovery_engine_with_search_context(user_prompt)
    
    # Triple ì •ë³´ë¥¼ ì ì ˆíˆ ì œí•œí•´ì„œ í¬í•¨
    max_triple_length = 800  # Triple ì •ë³´ ìµœëŒ€ ê¸¸ì´ (ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ ê³µê°„ í™•ë³´)
    triple_text = "\n".join(triples)
    
    if len(triple_text) > max_triple_length:
        triple_text = triple_text[:max_triple_length] + "..."
        logger.warning(f"Triple í…ìŠ¤íŠ¸ê°€ {len(triple_text)}ìë¡œ ì¶•ì†Œë¨")
    
    # í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼: ê²€ìƒ‰ìœ¼ë¡œ ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
    search_results = search_discovery_engine(user_prompt, max_results=10)
    search_context = _build_context_from_search_results(
        search_results.get("results", []), 
        search_results.get("summary"),
        max_context_length=700  # Tripleê³¼ ê· í˜• ë§ì¶¤
    )
    
    # ê°•í™”ëœ ì¿¼ë¦¬ ìƒì„±
    enhanced_query = f"""ì§ˆë¬¸: {user_prompt}

ë°ì´í„°ë² ì´ìŠ¤ Triple ì •ë³´:
{triple_text}

ê²€ìƒ‰ëœ ì¶”ê°€ ì°¸ê³  ì •ë³´:
{search_context}

ìœ„ ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì •í™•í•˜ê³  ìƒì„¸í•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”."""
    
    result = call_discovery_engine(enhanced_query)
    
    # ë©”íƒ€ë°ì´í„° ì¶”ê°€
    result["hybrid_metadata"] = {
        "triple_count": len(triples),
        "search_docs_found": len(search_results.get("results", [])),
        "combined_approach": True
    }
    
    return result

def generate_summary_answer(triple_answer: str, discovery_answer: str, user_prompt: str) -> Dict[str, Any]:
    """Triple ë‹µë³€ê³¼ Discovery Engine ë‹µë³€ì„ ê²°í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±"""
    # ë‹µë³€ë“¤ì„ ì ì ˆíˆ ìš”ì•½í•´ì„œ ì¿¼ë¦¬ ê¸¸ì´ ì œí•œ ë‚´ì—ì„œ ì²˜ë¦¬
    max_answer_length = 1500  # ê° ë‹µë³€ë‹¹ ìµœëŒ€ ê¸¸ì´
    
    truncated_triple = triple_answer[:max_answer_length] + "..." if len(triple_answer) > max_answer_length else triple_answer
    truncated_discovery = discovery_answer[:max_answer_length] + "..." if len(discovery_answer) > max_answer_length else discovery_answer
    
    combined_query = f"""ì§ˆë¬¸: {user_prompt}

ì°¸ê³ ë‹µë³€1: {truncated_triple}

ì°¸ê³ ë‹µë³€2: {truncated_discovery}

ìœ„ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”."""
    
    return call_discovery_engine(combined_query)