"""FastAPI ë¼ìš°í„° ëª¨ë“ˆ"""
import json
import base64
import asyncio
import logging
import os
import mimetypes
from datetime import datetime
from typing import Optional
from fastapi import APIRouter, File, UploadFile, HTTPException, Form
from fastapi.responses import JSONResponse, FileResponse, StreamingResponse

from ..config import Config
from ..auth import is_authenticated, get_storage_client
from ..database import query_spanner_triples, query_spanner_by_triple
from ..services.vertex_api import call_vertex_api, build_triple_only_payload, build_summary_payload
from ..services.triple_service import extract_triple_from_prompt
from ..services.validation_service import validate_response_relevance

logger = logging.getLogger(__name__)
router = APIRouter()

@router.get('/api/health')
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    from ..auth import is_authenticated
    return {
        "status": "healthy",
        "authenticated": is_authenticated(),
        "timestamp": datetime.now().isoformat()
    }

async def _build_vertex_payload(
    user_prompt: str,
    conversation_history: list,
    image_file: Optional[UploadFile],
    preloaded_triples: Optional[list] = None
) -> tuple:
    """Vertex AI ê²€ìƒ‰ì„ ìœ„í•œ í˜ì´ë¡œë“œ êµ¬ì„±"""
    user_content_parts = []
    if image_file:
        image_base64 = base64.b64encode(await image_file.read()).decode('utf-8')
        user_content_parts.append({"inlineData": {"mimeType": image_file.content_type, "data": image_base64}})

    if user_prompt:
        user_content_parts.append({"text": user_prompt})

    current_contents = conversation_history + [{"role": "user", "parts": user_content_parts}]

    # Triple grounding: ë¯¸ë¦¬ ë°›ì•„ì˜¨ ê²Œ ìˆìœ¼ë©´ ì“°ê³ , ì—†ìœ¼ë©´ ì¶”ì¶œ
    if preloaded_triples is not None:
        triples = preloaded_triples
    else:
        try:
            subject, predicate, object_ = await extract_triple_from_prompt(user_prompt)
            triples = query_spanner_by_triple(subject, predicate, object_)
        except Exception as e:
            logger.warning(f"Triple ì¶”ì¶œ ë˜ëŠ” ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            triples = []

    # grounding ë‚´ìš© system prompt ì•ì— ì‚½ì…
    if triples:
        triple_text = "\n".join(triples)
        current_contents.insert(0, {
            "role": "user",
            "parts": [{"text": f"[Spanner Triple Grounding]\n{triple_text}"}]
        })

    payload = {
        "systemInstruction": {"parts": [{"text": Config.load_system_instruction()}]},
        "contents": current_contents,
        "tools": [{"retrieval": {"vertexAiSearch": {"datastore": Config.get_datastore_path()}}}],
        "generationConfig": {
            "temperature": 0,
            "maxOutputTokens": 8192,
            "topP": 0.3
        }
    }

    return payload, current_contents

@router.post('/api/generate')
async def generate_content(userPrompt: str = Form(""), conversationHistory: str = Form("[]"), imageFile: Optional[UploadFile] = File(None)):
    """ë©”ì¸ ë‹µë³€ ìƒì„± ì—”ë“œí¬ì¸íŠ¸"""
    if not is_authenticated():
        raise HTTPException(status_code=503, detail="ì„œë²„ ì¸ì¦ ì‹¤íŒ¨ - Google Cloud ì¸ì¦ì„ í™•ì¸í•˜ì„¸ìš”")

    try:
        conversation_history = json.loads(conversationHistory)

        # ğŸ”¹ Step 1: Triple ê²€ìƒ‰ ë° ê¸°ë°˜ ì‘ë‹µ
        triples = query_spanner_triples(userPrompt)
        
        # Tripleì´ ì—†ìœ¼ë©´ ì¶”ì¶œí•˜ì—¬ ë‹¤ì‹œ ê²€ìƒ‰ ì‹œë„
        if not triples:
            try:
                subject, predicate, object_ = await extract_triple_from_prompt(userPrompt)
                triples = query_spanner_by_triple(subject, predicate, object_)
                logger.info(f"Fallback triple ê²€ìƒ‰ ê²°ê³¼: {len(triples)}ê±´")
            except Exception as e:
                logger.warning(f"Fallback triple ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

        # ğŸš€ Step 1&2: Triple ê¸°ë°˜ ì‘ë‹µê³¼ Vertex AI ê²€ìƒ‰ì„ ë³‘ë ¬ ì²˜ë¦¬
        triple_payload = await build_triple_only_payload(userPrompt, triples)
        full_payload, full_history = await _build_vertex_payload(userPrompt, conversation_history, imageFile, preloaded_triples=triples)
        
        # ë³‘ë ¬ API í˜¸ì¶œë¡œ ì†ë„ 2ë°° í–¥ìƒ
        triple_task = asyncio.create_task(call_vertex_api(triple_payload))
        vertex_task = asyncio.create_task(call_vertex_api(full_payload))
        
        triple_result, vertex_result = await asyncio.gather(triple_task, vertex_task)
        
        triple_text = triple_result['candidates'][0]['content']['parts'][0]['text']
        vertex_text = vertex_result['candidates'][0]['content']['parts'][0]['text']
        
        logger.info(json.dumps({
            "stage": "parallel_answers_generated",
            "triple_input": userPrompt,
            "triples_used": triples,
            "triple_answer_length": len(triple_text),
            "vertex_answer_length": len(vertex_text)
        }, ensure_ascii=False))

        # ğŸ”¹ Step 3&4: ìš”ì•½ê³¼ ê²€ì¦ì„ ë³‘ë ¬ ì²˜ë¦¬
        summary_payload = await build_summary_payload(triple_text, vertex_text, userPrompt)
        
        summary_task = asyncio.create_task(call_vertex_api(summary_payload))
        validation_task = asyncio.create_task(validate_response_relevance(userPrompt, f"{triple_text[:300]}..."))
        
        summary_result, is_relevant_preview = await asyncio.gather(summary_task, validation_task)
        summary_text = summary_result['candidates'][0]['content']['parts'][0]['text']
        
        # ìµœì¢… ê²€ì¦ (ìš”ì•½ ê²°ê³¼ ê¸°ì¤€)
        is_relevant = await validate_response_relevance(userPrompt, summary_text) if not is_relevant_preview else True
        
        if not is_relevant:
            logger.warning(f"ì‘ë‹µ ì—°ê´€ì„± ê²€ì¦ ì‹¤íŒ¨ - ì§ˆë¬¸: {userPrompt}")
            # ì²˜ìŒì„œë¹„ìŠ¤ì™€ ë¬´ê´€í•œ ì§ˆë¬¸ì— ëŒ€í•œ í‘œì¤€ ì‘ë‹µ
            summary_text = f"""ì£„ì†¡í•˜ì§€ë§Œ, **"{userPrompt}"**ì— ëŒ€í•œ ì •ë³´ëŠ” í˜„ì¬ ì œê³µí•´ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤.

**ì²˜ìŒì„œë¹„ìŠ¤**ì˜ ì œí’ˆ ë° ì„œë¹„ìŠ¤ì— ê´€í•œ êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´, ë” ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´:
- íŠ¹ì • ê¸°ëŠ¥ì˜ ì‚¬ìš© ë°©ë²•
- ì„¤ì • ë° êµ¬ì„± ê´€ë ¨ ë¬¸ì˜  
- ë¬¸ì œ í•´ê²° ë°©ë²•
- ì„œë¹„ìŠ¤ ì´ìš© ê°€ì´ë“œ

ì¶”ê°€ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë¬¸ì˜í•´ ì£¼ì„¸ìš”! ğŸ˜Š"""

        logger.info(json.dumps({
            "stage": "summary_answer_generated",
            "user_prompt": userPrompt,
            "is_relevant": is_relevant,
            "summary_answer": summary_text[:200] + "..." if len(summary_text) > 200 else summary_text
        }, ensure_ascii=False))

        return JSONResponse({
            "triple_answer": triple_text,
            "vertex_answer": vertex_text,
            "summary_answer": summary_text,
            "updatedHistory": full_history,
            "quality_check": {
                "relevance_passed": is_relevant,
                "triples_found": len(triples) > 0
            }
        })

    except Exception as e:
        logger.exception("ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/gcs/{bucket_name}/{file_path:path}")
async def proxy_gcs_file(bucket_name: str, file_path: str):
    """GCS íŒŒì¼ í”„ë¡ì‹œ ì—”ë“œí¬ì¸íŠ¸"""
    if not is_authenticated():
        raise HTTPException(status_code=503, detail="ìŠ¤í† ë¦¬ì§€ ì¸ì¦ ì‹¤íŒ¨")
    
    storage_client = get_storage_client()

    try:
        bucket = storage_client.bucket(bucket_name)
        blob = bucket.blob(file_path)
        if not blob.exists():
            raise HTTPException(status_code=404, detail="íŒŒì¼ ì—†ìŒ")

        def iterfile():
            with blob.open("rb") as f:
                yield from f

        content_type, _ = mimetypes.guess_type(file_path)
        content_type = content_type or "application/octet-stream"
        headers = {'Content-Disposition': f'inline; filename="{os.path.basename(file_path)}"'}
        return StreamingResponse(iterfile(), media_type=content_type, headers=headers)
    except Exception as e:
        logger.error("GCS í”„ë¡ì‹œ ì˜¤ë¥˜", exc_info=True)
        raise HTTPException(status_code=500, detail="íŒŒì¼ ì½ê¸° ì‹¤íŒ¨")