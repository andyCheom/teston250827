"""FastAPI ë¼ìš°í„° ëª¨ë“ˆ"""
import json
import base64
import asyncio
import logging
import os
import mimetypes
from datetime import datetime
from typing import Optional, Dict, Any
from fastapi import APIRouter, File, UploadFile, HTTPException, Form
from fastapi.responses import JSONResponse, FileResponse, StreamingResponse

from ..config import Config
from ..auth import is_authenticated, get_storage_client
from ..database import query_spanner_triples, query_spanner_by_triple
from ..services.vertex_api import call_vertex_api, build_triple_only_payload, build_summary_payload
from ..services.triple_service import extract_triple_from_prompt
from ..services.validation_service import validate_response_relevance
from ..services.discovery_engine_api import get_complete_discovery_answer

logger = logging.getLogger(__name__)
router = APIRouter()

@router.get('/api/health')
async def health_check():
    """ê¸°ë³¸ í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ - ë¹ ë¥¸ ì‘ë‹µ"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "service": "graphrag-api",
        "version": "2.0.0"
    }

@router.get('/api/health/detailed')
async def detailed_health_check():
    """ìƒì„¸ í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ - ì¸ì¦ í¬í•¨"""
    from main import get_auth_status
    try:
        # ë°±ê·¸ë¼ìš´ë“œ ì¸ì¦ ìƒíƒœ í™•ì¸ (ë¹ ë¥¸ ì‘ë‹µ)
        auth_status = get_auth_status()
        
        # ì‹¤ì œ ì¸ì¦ í•¨ìˆ˜ë„ í™•ì¸ (ì„ íƒì )
        try:
            from ..auth import is_authenticated
            detailed_auth_status = is_authenticated()
        except:
            detailed_auth_status = auth_status
        
        return {
            "status": "healthy" if auth_status else "degraded",
            "authenticated": auth_status,
            "detailed_auth": detailed_auth_status,
            "timestamp": datetime.now().isoformat(),
            "service": "graphrag-api",
            "version": "2.0.0",
            "components": {
                "auth": "ok" if auth_status else "warning",
                "api": "ok",
                "detailed_auth": "ok" if detailed_auth_status else "warning"
            }
        }
    except Exception as e:
        logger.warning(f"ì¸ì¦ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
        return {
            "status": "degraded",
            "authenticated": False,
            "timestamp": datetime.now().isoformat(),
            "service": "graphrag-api",
            "version": "2.0.0",
            "components": {
                "auth": "error",
                "api": "ok"
            },
            "error": str(e)
        }

async def _build_vertex_payload(
    user_prompt: str,
    conversation_history: list,
    image_file: Optional[UploadFile],
    preloaded_triples: Optional[list] = None
) -> tuple:
    """Vertex AI ê²€ìƒ‰ì„ ìœ„í•œ íŽ˜ì´ë¡œë“œ êµ¬ì„±"""
    user_content_parts = []
    if image_file:
        image_base64 = base64.b64encode(await image_file.read()).decode('utf-8')
        user_content_parts.append({"inlineData": {"mimeType": image_file.content_type, "data": image_base64}})

    if user_prompt:
        user_content_parts.append({"text": user_prompt})

    current_contents = conversation_history + [{"role": "user", "parts": user_content_parts}]

    # Triple grounding: ë¯¸ë¦¬ ë°›ì•„ì˜¨ ê²Œ ìžˆìœ¼ë©´ ì“°ê³ , ì—†ìœ¼ë©´ ì¶”ì¶œ
    if preloaded_triples is not None:
        triples = preloaded_triples
    else:
        try:
            subject, predicate, object_ = await extract_triple_from_prompt(user_prompt)
            triples = query_spanner_by_triple(subject, predicate, object_)
        except Exception as e:
            logger.warning(f"Triple ì¶”ì¶œ ë˜ëŠ” ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            triples = []

    # grounding ë‚´ìš© system prompt ì•žì— ì‚½ìž…
    if triples:
        triple_text = "\n".join(triples)
        current_contents.insert(0, {
            "role": "user",
            "parts": [{"text": f"[Spanner Triple Grounding]\n{triple_text}"}]
        })

    payload = {
        "systemInstruction": {"parts": [{"text": Config.load_system_instruction()}]},
        "contents": current_contents,
        "tools": [{"retrieval": {"vertexAiSearch": {"datastore": Config.get_datastore_path()}}}],
        "generationConfig": {
            "temperature": 0,
            "maxOutputTokens": 8192,
            "topP": 0.3
        }
    }

    return payload, current_contents

@router.post('/api/generate')
async def generate_content(userPrompt: str = Form(""), conversationHistory: str = Form("[]"), imageFile: Optional[UploadFile] = File(None)):
    """ë©”ì¸ ë‹µë³€ ìƒì„± ì—”ë“œí¬ì¸íŠ¸"""
    if not is_authenticated():
        raise HTTPException(status_code=503, detail="ì„œë²„ ì¸ì¦ ì‹¤íŒ¨ - Google Cloud ì¸ì¦ì„ í™•ì¸í•˜ì„¸ìš”")

    try:
        conversation_history = json.loads(conversationHistory)

        # ðŸ”¹ Step 1: Triple ê²€ìƒ‰ ë° ê¸°ë°˜ ì‘ë‹µ
        triples = query_spanner_triples(userPrompt)
        
        # Tripleì´ ì—†ìœ¼ë©´ ì¶”ì¶œí•˜ì—¬ ë‹¤ì‹œ ê²€ìƒ‰ ì‹œë„
        if not triples:
            try:
                subject, predicate, object_ = await extract_triple_from_prompt(userPrompt)
                triples = query_spanner_by_triple(subject, predicate, object_)
                logger.info(f"Fallback triple ê²€ìƒ‰ ê²°ê³¼: {len(triples)}ê±´")
            except Exception as e:
                logger.warning(f"Fallback triple ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

        # ðŸš€ Step 1&2: Triple ê¸°ë°˜ ì‘ë‹µê³¼ Vertex AI ê²€ìƒ‰ì„ ë³‘ë ¬ ì²˜ë¦¬
        triple_payload = await build_triple_only_payload(userPrompt, triples)
        full_payload, full_history = await _build_vertex_payload(userPrompt, conversation_history, imageFile, preloaded_triples=triples)
        
        # ë³‘ë ¬ API í˜¸ì¶œë¡œ ì†ë„ 2ë°° í–¥ìƒ
        triple_task = asyncio.create_task(call_vertex_api(triple_payload))
        vertex_task = asyncio.create_task(call_vertex_api(full_payload))
        
        triple_result, vertex_result = await asyncio.gather(triple_task, vertex_task)
        
        triple_text = triple_result['candidates'][0]['content']['parts'][0]['text']
        vertex_text = vertex_result['candidates'][0]['content']['parts'][0]['text']
        
        logger.info(json.dumps({
            "stage": "parallel_answers_generated",
            "triple_input": userPrompt,
            "triples_used": triples,
            "triple_answer_length": len(triple_text),
            "vertex_answer_length": len(vertex_text)
        }, ensure_ascii=False))

        # ðŸ”¹ Step 3&4: ìš”ì•½ê³¼ ê²€ì¦ì„ ë³‘ë ¬ ì²˜ë¦¬
        summary_payload = await build_summary_payload(triple_text, vertex_text, userPrompt)
        
        summary_task = asyncio.create_task(call_vertex_api(summary_payload))
        validation_task = asyncio.create_task(validate_response_relevance(userPrompt, f"{triple_text[:300]}..."))
        
        summary_result, is_relevant_preview = await asyncio.gather(summary_task, validation_task)
        summary_text = summary_result['candidates'][0]['content']['parts'][0]['text']
        
        # ìµœì¢… ê²€ì¦ (ìš”ì•½ ê²°ê³¼ ê¸°ì¤€)
        is_relevant = await validate_response_relevance(userPrompt, summary_text) if not is_relevant_preview else True
        
        if not is_relevant:
            logger.warning(f"ì‘ë‹µ ì—°ê´€ì„± ê²€ì¦ ì‹¤íŒ¨ - ì§ˆë¬¸: {userPrompt}")
            # ì²˜ìŒì„œë¹„ìŠ¤ì™€ ë¬´ê´€í•œ ì§ˆë¬¸ì— ëŒ€í•œ í‘œì¤€ ì‘ë‹µ
            summary_text = f"""ì£„ì†¡í•˜ì§€ë§Œ, **"{userPrompt}"**ì— ëŒ€í•œ ì •ë³´ëŠ” í˜„ìž¬ ì œê³µí•´ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤.

**ì²˜ìŒì„œë¹„ìŠ¤**ì˜ ì œí’ˆ ë° ì„œë¹„ìŠ¤ì— ê´€í•œ êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´, ë” ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´:
- íŠ¹ì • ê¸°ëŠ¥ì˜ ì‚¬ìš© ë°©ë²•
- ì„¤ì • ë° êµ¬ì„± ê´€ë ¨ ë¬¸ì˜  
- ë¬¸ì œ í•´ê²° ë°©ë²•
- ì„œë¹„ìŠ¤ ì´ìš© ê°€ì´ë“œ

ì¶”ê°€ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“  ë¬¸ì˜í•´ ì£¼ì„¸ìš”! ðŸ˜Š"""

        logger.info(json.dumps({
            "stage": "summary_answer_generated",
            "user_prompt": userPrompt,
            "is_relevant": is_relevant,
            "summary_answer": summary_text[:200] + "..." if len(summary_text) > 200 else summary_text
        }, ensure_ascii=False))

        return JSONResponse({
            "triple_answer": triple_text,
            "vertex_answer": vertex_text,
            "summary_answer": summary_text,
            "updatedHistory": full_history,
            "quality_check": {
                "relevance_passed": is_relevant,
                "triples_found": len(triples) > 0
            }
        })

    except Exception as e:
        logger.exception("ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/gcs/{bucket_name}/{file_path:path}")
async def proxy_gcs_file(bucket_name: str, file_path: str):
    """GCS íŒŒì¼ í”„ë¡ì‹œ ì—”ë“œí¬ì¸íŠ¸"""
    if not is_authenticated():
        raise HTTPException(status_code=503, detail="ìŠ¤í† ë¦¬ì§€ ì¸ì¦ ì‹¤íŒ¨")
    
    storage_client = get_storage_client()

    try:
        bucket = storage_client.bucket(bucket_name)
        blob = bucket.blob(file_path)
        if not blob.exists():
            raise HTTPException(status_code=404, detail="íŒŒì¼ ì—†ìŒ")

        def iterfile():
            with blob.open("rb") as f:
                yield from f

        content_type, _ = mimetypes.guess_type(file_path)
        content_type = content_type or "application/octet-stream"
        headers = {'Content-Disposition': f'inline; filename="{os.path.basename(file_path)}"'}
        return StreamingResponse(iterfile(), media_type=content_type, headers=headers)
    except Exception as e:
        logger.error("GCS í”„ë¡ì‹œ ì˜¤ë¥˜", exc_info=True)
        raise HTTPException(status_code=500, detail="íŒŒì¼ ì½ê¸° ì‹¤íŒ¨")

@router.post('/api/discovery-answer')
async def discovery_answer(userPrompt: str = Form("")):
    """Discovery Engine Answer API í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    if not is_authenticated():
        raise HTTPException(status_code=503, detail="ì„œë²„ ì¸ì¦ ì‹¤íŒ¨ - Google Cloud ì¸ì¦ì„ í™•ì¸í•˜ì„¸ìš”")

    try:
        # Discovery Engineì„ í†µí•œ ë‹µë³€ ìƒì„±
        discovery_result = await get_complete_discovery_answer(userPrompt)
        
        logger.info(json.dumps({
            "stage": "discovery_answer_generated",
            "user_prompt": userPrompt,
            "answer_length": len(discovery_result.get("answer_text", "")),
            "citations_count": len(discovery_result.get("citations", [])),
            "search_results_count": len(discovery_result.get("search_results", []))
        }, ensure_ascii=False))

        return JSONResponse({
            "answer": discovery_result.get("answer_text", ""),
            "citations": discovery_result.get("citations", []),
            "search_results": discovery_result.get("search_results", []),
            "related_questions": discovery_result.get("related_questions", []),
            "metadata": {
                "query_id": discovery_result.get("query_id"),
                "session_id": discovery_result.get("session_id"),
                "engine_type": "discovery_engine_answer"
            }
        })

    except Exception as e:
        logger.exception("Discovery Engine Answer API ì˜¤ë¥˜")
        raise HTTPException(status_code=500, detail=f"Discovery Engine ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {str(e)}")

@router.post('/api/compare-answers')
async def compare_answers(userPrompt: str = Form("")):
    """ê¸°ì¡´ ë°©ì‹ê³¼ Discovery Engine Answer API ë¹„êµ í…ŒìŠ¤íŠ¸"""
    if not is_authenticated():
        raise HTTPException(status_code=503, detail="ì„œë²„ ì¸ì¦ ì‹¤íŒ¨ - Google Cloud ì¸ì¦ì„ í™•ì¸í•˜ì„¸ìš”")

    try:
        # ë³‘ë ¬ë¡œ ë‘ ë°©ì‹ ëª¨ë‘ ì‹¤í–‰
        original_task = asyncio.create_task(_get_original_answer(userPrompt))
        discovery_task = asyncio.create_task(get_complete_discovery_answer(userPrompt))
        
        original_result, discovery_result = await asyncio.gather(
            original_task, discovery_task, return_exceptions=True
        )
        
        # ê²°ê³¼ ì •ë¦¬
        response = {
            "user_prompt": userPrompt,
            "timestamp": datetime.now().isoformat(),
            "original_method": {},
            "discovery_method": {}
        }
        
        # ê¸°ì¡´ ë°©ì‹ ê²°ê³¼ ì²˜ë¦¬
        if isinstance(original_result, Exception):
            response["original_method"] = {
                "status": "error",
                "error": str(original_result)
            }
        else:
            response["original_method"] = {
                "status": "success",
                "triple_answer": original_result.get("triple_answer", ""),
                "vertex_answer": original_result.get("vertex_answer", ""),
                "summary_answer": original_result.get("summary_answer", ""),
                "quality_check": original_result.get("quality_check", {})
            }
        
        # Discovery Engine ê²°ê³¼ ì²˜ë¦¬
        if isinstance(discovery_result, Exception):
            response["discovery_method"] = {
                "status": "error", 
                "error": str(discovery_result)
            }
        else:
            response["discovery_method"] = {
                "status": "success",
                "answer": discovery_result.get("answer_text", ""),
                "citations_count": len(discovery_result.get("citations", [])),
                "search_results_count": len(discovery_result.get("search_results", [])),
                "related_questions": discovery_result.get("related_questions", [])
            }
        
        return JSONResponse(response)

    except Exception as e:
        logger.exception("ë‹µë³€ ë¹„êµ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜")
        raise HTTPException(status_code=500, detail=f"ë‹µë³€ ë¹„êµ ì‹¤íŒ¨: {str(e)}")

async def _get_original_answer(user_prompt: str) -> Dict[str, Any]:
    """ê¸°ì¡´ ë°©ì‹ì˜ ë‹µë³€ ìƒì„± (ë‚´ë¶€ í—¬í¼ í•¨ìˆ˜)"""
    # ê¸°ì¡´ /api/generate ë¡œì§ì„ ìž¬ì‚¬ìš©
    triples = query_spanner_triples(user_prompt)
    
    if not triples:
        try:
            subject, predicate, object_ = await extract_triple_from_prompt(user_prompt)
            triples = query_spanner_by_triple(subject, predicate, object_)
        except Exception as e:
            logger.warning(f"Fallback triple ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

    # ë³‘ë ¬ ì²˜ë¦¬
    triple_payload = await build_triple_only_payload(user_prompt, triples)
    full_payload, _ = await _build_vertex_payload(user_prompt, [], None, preloaded_triples=triples)
    
    triple_task = asyncio.create_task(call_vertex_api(triple_payload))
    vertex_task = asyncio.create_task(call_vertex_api(full_payload))
    
    triple_result, vertex_result = await asyncio.gather(triple_task, vertex_task)
    
    triple_text = triple_result['candidates'][0]['content']['parts'][0]['text']
    vertex_text = vertex_result['candidates'][0]['content']['parts'][0]['text']
    
    # ìš”ì•½ ìƒì„±
    summary_payload = await build_summary_payload(triple_text, vertex_text, user_prompt)
    summary_result = await call_vertex_api(summary_payload)
    summary_text = summary_result['candidates'][0]['content']['parts'][0]['text']
    
    # ê²€ì¦
    is_relevant = await validate_response_relevance(user_prompt, summary_text)
    
    return {
        "triple_answer": triple_text,
        "vertex_answer": vertex_text, 
        "summary_answer": summary_text,
        "quality_check": {
            "relevance_passed": is_relevant,
            "triples_found": len(triples) > 0
        }
    }